@inproceedings{belgaCarouselImprovingAccuracy2022,
  title = {Carousel: Improving the Accuracy of Virtual Reality Assessments for Inspection Training Tasks},
  shorttitle = {Carousel},
  booktitle = {28th {{ACM Symposium}} on {{Virtual Reality Software}} and {{Technology}}},
  author = {Belga, Jacob and Do, Tiffany D. and Ghamandi, Ryan and McMahan, Ryan P. and LaViola, Joseph J.},
  year = {2022},
  month = nov,
  pages = {1--10},
  publisher = {{ACM}},
  address = {{Tsukuba Japan}},
  doi = {10.1145/3562939.3565618},
  urldate = {2023-10-28},
  abstract = {Training simulations in virtual reality (VR) have become a focal point of both research and development due to allowing users to familiarize themselves with procedures and tasks without needing physical objects to interact with or needing to be physically present. However, the increasing popularity of VR training paradigms raises the question: Are VR-based training assessments accurate? Many VR training programs, particularly those focused on inspection tasks, employ simple pass or fail assessments. However, these types of assessments do not necessarily reflect the user's knowledge.},
  isbn = {978-1-4503-9889-3},
  langid = {english}
}

@inproceedings{doDesigningVirtualPedagogical2021,
  title = {Designing Virtual Pedagogical Agents and Mentors for Extended Reality},
  booktitle = {2021 {{IEEE International Symposium}} on {{Mixed}} and {{Augmented Reality Adjunct}} ({{ISMAR-Adjunct}})},
  author = {Do, Tiffany D.},
  year = {2021},
  month = oct,
  pages = {476--479},
  publisher = {{IEEE}},
  address = {{Bari, Italy}},
  doi = {10.1109/ISMAR-Adjunct54149.2021.00112},
  urldate = {2023-10-28},
  abstract = {The use of virtual and augmented reality for educational purposes has seen a rapid increase in interest in recent years. Extended reality offers unique affordances to learners, and can enhance learning. Specifically, we are interested in the use of pedagogical agents in extended reality due to their potential to increase student motivation and learning. However, the design of pedagogical agents in extended reality is still a nascent area of study, which can be important in an immersive environment where social cues can be more salient. Pedagogical agent design aspects such as speech, appearance, and modality can prime social cues and affect learning outcomes and instructor perception. In this paper, we propose a project to investigate auditory and visual social cues of pedagogical agents in XR such as speech, ethnicity, and modality.},
  isbn = {978-1-66541-298-8},
  langid = {english}
}

@inproceedings{doEffectsEmbodiedPedagogical2022,
  title = {The Effects of an Embodied Pedagogical Agent's Synthetic Speech Accent on Learning Outcomes},
  booktitle = {{{INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION}}},
  author = {Do, Tiffany D. and Akter, Mamtaj and Choudhary, Zubin and Azevedo, Roger and McMahan, Ryan P.},
  year = {2022},
  month = nov,
  pages = {198--206},
  publisher = {{ACM}},
  address = {{Bengaluru India}},
  doi = {10.1145/3536221.3556587},
  urldate = {2023-10-28},
  abstract = {Modern text-to-speech engines can be an effective speech choice for embodied virtual pedagogical agents. However, it is not known how synthesized accents influence learning outcomes and perceptions of the agent. In this paper, we conducted a between-subjects experiment (n=60) to determine the effect of a pedagogical agent's machine synthesized text-to-speech accent (United States English or Indian English) on learning outcomes and perceptions of the agent for students in the United States. Our results indicate that learner gender interacts with synthesized speech accent to significantly affect learning outcomes and perceptions of the agent. Our results reveal that a foreign synthetic speech accent may affect the learning outcomes of female university students (n=30), but not male university students (n=30). Finally, our results indicate that learner gender interacts with synthesized speech accent to affect perceptions of the pedagogical agent's human-likeness. We provide novel insights on the differences between male and female learners for interactions with pedagogical agents with synthetic TTS accents.},
  isbn = {978-1-4503-9390-4},
  langid = {english}
}

@inproceedings{doEffectsObjectShape2020,
  title = {The Effects of Object Shape, Fidelity, Color, and Luminance on Depth Perception in Handheld Mobile Augmented Reality},
  booktitle = {2020 {{IEEE International Symposium}} on {{Mixed}} and {{Augmented Reality}} ({{ISMAR}})},
  author = {Do, Tiffany D. and LaViola, Joseph J. and McMahan, Ryan P.},
  year = {2020},
  month = nov,
  pages = {64--72},
  publisher = {{IEEE}},
  address = {{Porto de Galinhas, Brazil}},
  doi = {10.1109/ISMAR50242.2020.00026},
  urldate = {2023-10-28},
  abstract = {Depth perception of objects can greatly affect a user's experience of an augmented reality (AR) application. Many AR applications require depth matching of real and virtual objects and have the possibility to be influenced by depth cues. Color and luminance are depth cues that have been traditionally studied in two-dimensional (2D) objects. However, there is little research investigating how the properties of three-dimensional (3D) virtual objects interact with color and luminance to affect depth perception, despite the substantial use of 3D objects in visual applications. In this paper, we present the results of a paired comparison experiment that investigates the effects of object shape, fidelity, color, and luminance on depth perception of 3D objects in handheld mobile AR. The results of our study indicate that bright colors are perceived as nearer than dark colors for a high-fidelity, simple 3D object, regardless of hue. Additionally, bright red is perceived as nearer than any other color. These effects were not observed for a low-fidelity version of the simple object or for a more-complex 3D object. High-fidelity objects had more perceptual differences than low-fidelity objects, indicating that fidelity interacts with color and luminance to affect depth perception. These findings reveal how the properties of 3D models influence the effects of color and luminance on depth perception in handheld mobile AR and can help developers select colors for their applications.},
  isbn = {978-1-72818-508-8},
  langid = {english}
}

@inproceedings{doNewUncannyValley2022,
  title = {A New Uncanny Valley? {{The}} Effects of Speech Fidelity and Human Listener Gender on Social Perceptions of a Virtual-Human Speaker},
  shorttitle = {A New Uncanny Valley?},
  booktitle = {{{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Do, Tiffany D. and McMahan, Ryan P. and Wisniewski, Pamela J.},
  year = {2022},
  month = apr,
  pages = {1--11},
  publisher = {{ACM}},
  address = {{New Orleans LA USA}},
  doi = {10.1145/3491102.3517564},
  urldate = {2023-10-28},
  abstract = {Virtual humans can be used to deliver persuasive arguments; yet, those with synthetic text-to-speech (TTS) have been perceived less favorably than those with recorded human speech. In this paper, we investigate standard concatenative TTS and more advanced neural TTS. We conducted a 3x2 between-subjects experiment (n=79) to evaluate the effect of a virtual human's speech fidelity at three levels (Standard TTS, Neural TTS, and Human speech) and the listener's gender (male or female) on perceptions and persuasion. We found that the virtual human was perceived as significantly less trustworthy by both genders, if they used neural TTS compared to human speech, while male listeners (but not females) also perceived standard TTS as less trustworthy than human speech. Our findings indicate that neural TTS may not be an effective choice for persuasive virtual humans and that gender of the listener plays a role in how virtual humans are perceived.},
  isbn = {978-1-4503-9157-3},
  langid = {english}
}

@inproceedings{doUsingCollaborativeFiltering2020a,
  title = {Using Collaborative Filtering to Recommend Champions in League of Legends},
  booktitle = {2020 {{IEEE Conference}} on {{Games}} ({{CoG}})},
  author = {Do, Tiffany D. and Yu, Dylan S. and Anwer, Salman and Wang, Seong Ioi},
  year = {2020},
  month = aug,
  pages = {650--653},
  publisher = {{IEEE}},
  address = {{Osaka, Japan}},
  doi = {10.1109/CoG47356.2020.9231735},
  urldate = {2023-10-28},
  abstract = {League of Legends (LoL), one of the most widely played computer games in the world, has over 140 playable characters known as champions that have highly varying play styles. However, there is not much work on providing champion recommendations to a player in LoL. In this paper, we propose that a recommendation system based on a collaborative filtering approach using singular value decomposition provides champion recommendations that players enjoy. We discuss the implementation behind our recommendation system and also evaluate the practicality of our system using a preliminary user study. Our results indicate that players significantly preferred recommendations from our system over random recommendations.},
  isbn = {978-1-72814-533-4},
  langid = {english}
}

@inproceedings{doUsingMachineLearning2021,
  title = {Using Machine Learning to Predict Game Outcomes Based on Player-Champion Experience in League of Legends},
  booktitle = {The 16th {{International Conference}} on the {{Foundations}} of {{Digital Games}} ({{FDG}}) 2021},
  author = {Do, Tiffany D. and Wang, Seong Ioi and Yu, Dylan S. and McMillian, Matthew G. and McMahan, Ryan P.},
  year = {2021},
  month = aug,
  pages = {1--5},
  publisher = {{ACM}},
  address = {{Montreal QC Canada}},
  doi = {10.1145/3472538.3472579},
  urldate = {2023-10-28},
  abstract = {League of Legends (LoL) is the most widely played multiplayer online battle arena (MOBA) game in the world. An important aspect of LoL is competitive ranked play, which utilizes a skill-based matchmaking system to form fair teams. However, players' skill levels vary widely depending on which champion, or hero, that they choose to play as. In this paper, we propose a method for predicting game outcomes in ranked LoL games based on players' experience with their selected champion. Using a deep neural network, we found that game outcomes can be predicted with 75.1\% accuracy after all players have selected champions, which occurs before gameplay begins. Our results have important implications for playing LoL and matchmaking. Firstly, individual champion skill plays a significant role in the outcome of a match, regardless of team composition. Secondly, even after the skill-based matchmaking, there is still a wide variance in team skill before gameplay begins. Finally, players should only play champions that they have mastered, if they want to win games.},
  isbn = {978-1-4503-8422-3},
  langid = {english}
}

@inproceedings{mooreIdentifyingVirtualReality2023,
  title = {Identifying Virtual Reality Users across Domain-Specific Tasks: A Systematic Investigation of Tracked Features for Assembly},
  booktitle = {2023 {{IEEE International Symposium}} on {{Mixed}} and {{Augmented Reality}} ({{ISMAR}})},
  author = {Moore, Alec G and Do, Tiffany D and Ruozzi, Nicholas and McMahan, Ryan P},
  year = {2023},
  month = oct,
  publisher = {{IEEE}},
  abstract = {Recently, there has been much interest in using virtual reality (VR) tracking data to authenticate or identify users. Most prior research has relied on task-specific characteristics but newer studies have begun investigating task-agnostic, domain-specific approaches. In this paper, we present one of the first systematic investigations of how different combinations of VR tracked devices (i.e., the headset, dominant hand controller, and non-dominant hand controller) and their spatial representations (i.e., position and/or rotation as Euler angles, quaternions, or 6D) affect identification accuracy for domain-specific approaches. We conducted a user study (n = 45) involving participants learning how to assemble two distinct fullscale constructions. Our results indicate that more tracked devices improve identification accuracies for the same assembly task, but only headset features afford the best accuracies across the domainspecific tasks. Our results also indicate that spatial features involving position and any rotation yield better accuracies than either alone.},
  langid = {english}
}
